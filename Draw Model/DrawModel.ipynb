{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8jEfUyElg-y",
        "outputId": "f8b45b5f-b406-4e79-dd09-e57fed93f129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: turicreate in /usr/local/lib/python3.7/dist-packages (6.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.15.0)\n",
            "Requirement already satisfied: numba<0.51.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (0.50.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.7.3)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from turicreate) (2.23.0)\n",
            "Requirement already satisfied: tensorflow<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (2.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.18.5)\n",
            "Requirement already satisfied: decorator>=4.0.9 in /usr/local/lib/python3.7/dist-packages (from turicreate) (4.4.2)\n",
            "Requirement already satisfied: coremltools==3.3 in /usr/local/lib/python3.7/dist-packages (from turicreate) (3.3)\n",
            "Requirement already satisfied: resampy==0.2.1 in /usr/local/lib/python3.7/dist-packages (from turicreate) (0.2.1)\n",
            "Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.3.5)\n",
            "Requirement already satisfied: prettytable==0.7.2 in /usr/local/lib/python3.7/dist-packages (from turicreate) (0.7.2)\n",
            "Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==3.3->turicreate) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<0.51.0->turicreate) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<0.51.0->turicreate) (0.33.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->turicreate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->turicreate) (2022.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (2022.9.24)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.3.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.8)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.38.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install turicreate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "H2AuBr_Eohad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import some constants\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Get data files\n",
        "watch_round1_session1 = pd.read_csv('watch_round1_session1.csv')\n",
        "watch_round1_session2 = pd.read_csv('watch_round1_session2.csv')\n",
        "watch_round1_session3 = pd.read_csv('watch_round1_session3.csv')\n",
        "watch_round2_session1 = pd.read_csv('watch_round2_session1.csv')\n",
        "watch_round2_session2 = pd.read_csv('watch_round2_session2.csv')\n",
        "watch_round2_session3 = pd.read_csv('watch_round2_session3.csv')\n",
        "\n",
        "round1_files = [watch_round1_session1, watch_round1_session2, watch_round1_session3]\n",
        "round2_files = [watch_round2_session1, watch_round2_session2, watch_round2_session3]\n",
        "\n",
        "# Load session activity log\n",
        "with open(\"sessions_log.json\", \"r\") as f:\n",
        "    session_log = json.loads(f.read())\n",
        "\n",
        "### Constants and Functions ###\n",
        "# Two rounds of data collection\n",
        "rounds = ['round1', 'round2']\n",
        "# For each data collection round there was 1 user participating\n",
        "users_per_round = 1\n",
        "# For each data collection round there were 3 separate sessions\n",
        "sessons_per_round = 3\n",
        "\n",
        "# Timestamp format to follow\n",
        "time_format = '%Y-%m-%d %H:%M:%S.%f'\n",
        "\n",
        "# Columns to use from the csv data\n",
        "session_sensor_data_columns = [\n",
        "    \"loggingTime(txt)\",\n",
        "    \"motionRotationRateX(rad/s)\",\n",
        "    \"motionRotationRateY(rad/s)\",\n",
        "    \"motionRotationRateZ(rad/s)\",\n",
        "    \"motionUserAccelerationX(G)\",\n",
        "    \"motionUserAccelerationY(G)\",\n",
        "    \"motionUserAccelerationZ(G)\"\n",
        "]\n",
        "\n",
        "# Helper functions\n",
        "def convert_timestamp(x):\n",
        "    return datetime.fromtimestamp(x).strftime(time_format)\n",
        "\n",
        "def chunks(l, n):\n",
        "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i + n]\n",
        "\n",
        "def make_delta(time):\n",
        "    h, m, seconds = time.split(':')\n",
        "    s, milli = seconds.split('.')\n",
        "    milli = milli + str(0)\n",
        "    return timedelta(hours=int(h), minutes=int(m), seconds=int(s), milliseconds=int(milli))\n",
        "\n",
        "################################\n",
        "\n",
        "# Load Activity Data\n",
        "\n",
        "# Iterate through all user session logs\n",
        "# Map to the proper activity label\n",
        "# Concatenate into a single activity dataframe\n",
        "\n",
        "session_id = 0 # Keep track of session id: unique to each user file\n",
        "activity_data = pd.DataFrame()\n",
        "\n",
        "# For each round of data collection\n",
        "for rnd in rounds:\n",
        "    print(f'Parsing {rnd} activity data', flush=True)\n",
        "    # Grab the files for this round\n",
        "    if(rnd == 'round1'):\n",
        "        rnd_files = round1_files\n",
        "    else:\n",
        "        rnd_files = round2_files\n",
        "    # Group files for the round by session\n",
        "    rnd_session_files = list(chunks(rnd_files, users_per_round))\n",
        "    # Should have the right number of sessions, each file within a session is a unique user\n",
        "    assert len(rnd_session_files) == sessons_per_round\n",
        "    # For each session (3) within the round\n",
        "    for session in range(sessons_per_round):\n",
        "        print(f'Parsing session {session + 1} data files', flush=True)\n",
        "        # Grab the user activity log files for this session\n",
        "        session_files = rnd_session_files[session]\n",
        "        # Grab the activity labels for this session\n",
        "        session_log_data = session_log[rnd]['session' + str(1+session)]\n",
        "        # For each user\n",
        "        for user_file in session_files:\n",
        "            # Load user file for this session - fix timestamp and add session id\n",
        "            user_log_df = user_file[session_sensor_data_columns]\n",
        "            user_log_df[\"loggingTime\"] = user_log_df[\"loggingTime(txt)\"].apply(lambda x: pd.to_datetime(x).replace(tzinfo=None))\n",
        "            user_log_df.drop(\"loggingTime(txt)\", axis=1, inplace=True)\n",
        "            user_log_df[\"sessionId\"] = session_id\n",
        "            session_id += 1\n",
        "            # Convert timestamp and make sure it's ordered appropriately\n",
        "            user_log_df.sort_values(by=\"loggingTime\", ascending=True)\n",
        "            first_val = user_log_df[\"loggingTime\"][0]\n",
        "            # Get the logs that contain the activity labels for this session\n",
        "            user_session_activity_df = pd.DataFrame({\n",
        "                'activity': pd.Series([s[0] for s in session_log_data], dtype=str),\n",
        "                'loggingTime': pd.Series([first_val + make_delta(s[1]) for s in session_log_data])\n",
        "            }).sort_values(by=\"loggingTime\", ascending=True)\n",
        "            # Fuzzy merge on timestamps to map user logs to activity labels\n",
        "            user_log_cleaned = pd.merge_asof(\n",
        "                left=user_log_df,\n",
        "                right=user_session_activity_df,\n",
        "                on='loggingTime',\n",
        "                direction='forward'\n",
        "            )\n",
        "            activity_data = pd.concat((activity_data, user_log_cleaned))\n",
        "            \n",
        "# In the end, you will have the fully cleaned and joined activity data file\n",
        "activity_data.to_csv(r'/content/watch_activity_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKEmYzZHDIp1",
        "outputId": "3f397c55-314b-478e-ebf8-12e2651230f9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing round1 activity data\n",
            "Parsing session 1 data files\n",
            "Parsing session 2 data files\n",
            "Parsing session 3 data files\n",
            "Parsing round2 activity data\n",
            "Parsing session 1 data files\n",
            "Parsing session 2 data files\n",
            "Parsing session 3 data files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import turicreate as tc\n",
        "import shutil\n",
        "\n",
        "# Remove previous data files\n",
        "shutil.rmtree(r'test/')\n",
        "shutil.rmtree(r'train/')\n",
        "\n",
        "# Column name mappings\n",
        "cols = {\n",
        "    \"motionRotationRateX(rad/s)\": \"rotation_x\",\n",
        "    \"motionRotationRateY(rad/s)\": \"rotation_y\",\n",
        "    \"motionRotationRateZ(rad/s)\": \"rotation_z\",\n",
        "    \"motionUserAccelerationX(G)\": \"acceleration_x\",\n",
        "    \"motionUserAccelerationY(G)\": \"acceleration_y\",\n",
        "    \"motionUserAccelerationZ(G)\": \"acceleration_z\",\n",
        "    \"sessionId\": \"session_id\",\n",
        "    \"activity\": \"activity\"\n",
        "}\n",
        "csv_cols = [\"rotation_x\", \"rotation_y\", \"rotation_z\", \"acceleration_x\", \"acceleration_y\", \"acceleration_z\"]\n",
        "\n",
        "# Load csv data and rename columns\n",
        "sf = tc.SFrame.read_csv(\"watch_activity_data.csv\")[list(cols.keys())].rename(cols)\n",
        "\n",
        "# Remove missing activies\n",
        "sf = sf[sf['activity'] != '']\n",
        "acts = sf['activity'].unique()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train, test = tc.activity_classifier.util.random_split_by_session(sf, session_id='session_id', fraction=0.7)\n",
        "\n",
        "# Write out training data\n",
        "path = \"train/\"\n",
        "os.mkdir(path)\n",
        "\n",
        "for a in acts:\n",
        "    # Check for folder\n",
        "    cls_path = path + a + \"/\"\n",
        "    if not os.path.exists(cls_path):\n",
        "        os.mkdir(cls_path)\n",
        "    # Split data by activity & session and write to file\n",
        "    sf_act = train[train['activity'] == a]\n",
        "    for s in sf_act['session_id'].unique():\n",
        "        sf_act[sf_act['session_id'] == s][csv_cols].save(cls_path + str(s) + \".csv\")\n",
        "\n",
        "# Write out testing data\n",
        "path = \"test/\"\n",
        "os.mkdir(path)\n",
        "\n",
        "for a in acts:\n",
        "    # Check for folder\n",
        "    cls_path = path + a + \"/\"\n",
        "    if not os.path.exists(cls_path):\n",
        "        os.mkdir(cls_path)\n",
        "    # Split data by activity & session and write to file\n",
        "    sf_act = test[test['activity'] == a]\n",
        "    for s in sf_act['session_id'].unique():\n",
        "        sf_act[sf_act['session_id'] == s][csv_cols].save(cls_path + str(s) + \".csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "uWebti-FDHF3",
        "outputId": "2c6ff2bd-5ed4-46f1-d5f5-7b0c902a9d22"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Finished parsing file /content/watch_activity_data.csv"
            ],
            "text/html": [
              "<pre>Finished parsing file /content/watch_activity_data.csv</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing completed. Parsed 100 lines in 0.279249 secs."
            ],
            "text/html": [
              "<pre>Parsing completed. Parsed 100 lines in 0.279249 secs.</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "Inferred types from first 100 line(s) of file as \n",
            "column_type_hints=[int,float,float,float,float,float,float,str,int,str]\n",
            "If parsing fails due to incorrect types, you can correct\n",
            "the inferred type list above and pass it to read_csv in\n",
            "the column_type_hints argument\n",
            "------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Finished parsing file /content/watch_activity_data.csv"
            ],
            "text/html": [
              "<pre>Finished parsing file /content/watch_activity_data.csv</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing completed. Parsed 57026 lines in 0.225533 secs."
            ],
            "text/html": [
              "<pre>Parsing completed. Parsed 57026 lines in 0.225533 secs.</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}